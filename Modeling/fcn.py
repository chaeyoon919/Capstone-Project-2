# -*- coding: utf-8 -*-
"""FCN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zw10a8qqnLmerdfIbmpk2LjLRyjlwfYp
"""

# 색상 코드 정의(32개)
color_codes = {
    'Animal':[64, 128, 64],
  'Archway':[192, 0, 128],
  'Bicyclist':[0, 128, 192],
  'Bridge':[0, 128, 64],
  'Building':[128, 0, 0],
  'Car':[64, 0, 128],
  'CartLuggagePram':[64, 0, 192],
  'Child':[192, 128, 64],
  'Column_Pole':[192, 192, 128],
  'Fence':[64, 64, 128],
  'LaneMkgsDriv':[128, 0, 192],
  'LaneMkgsNonDriv':[192, 0, 64],
  'Misc_Text':[128, 128, 64],
  'MotorcycleScooter':[192, 0, 192],
  'OtherMoving':[128, 64, 64],
  'ParkingBlock':[64, 192, 128],
  'Pedestrian':[64, 64, 0],
  'Road':[128, 64, 128],
  'RoadShoulder':[128, 128, 192],
  'Sidewalk':[0, 0, 192],
  'SignSymbol':[192, 128, 128],
  'Sky':[128, 128, 128],
  'SUVPickupTruck':[64, 128, 192],
  'TrafficCone':[0, 0, 64],
  'TrafficLight':[0, 64, 64],
  'Train':[192, 64, 128],
  'Tree':[128, 128, 0],
  'Truck_Bus':[192, 128, 192],
  'Tunnel':[64, 0, 64],
  'VegetationMisc':[192, 192, 0],
  'Void':[0, 0, 0],
  'Wall':[64, 192, 0] 
}

# MeanIou 함수 정의
class MeanIoU(object):

    def __init__(self, num_classes):
        super().__init__()

        self.num_classes = num_classes

    def mean_iou(self, y_true, y_pred):
      
        return tf.compat.v1.py_func(self._mean_iou, [y_true, y_pred], tf.float32)

    def _mean_iou(self, y_true, y_pred):
      
        """Computes the mean intesection over union using numpy.
        Args:
            y_true (tensor): True labels.
            y_pred (tensor): Predictions of the same shape as y_true.
        Returns:
            The mean intersection over union (np.float32).
        """
        # Compute the confusion matrix to get the number of true positives,
        # false positives, and false negatives
        # Convert predictions and target from categorical to integer format
        target = np.argmax(y_true, axis=-1).ravel()
        predicted = np.argmax(y_pred, axis=-1).ravel()

        # Trick for bincounting 2 arrays together
        x = predicted + self.num_classes * target
        bincount_2d = np.bincount(
            x.astype(np.int32), minlength=self.num_classes**2
        )
        assert bincount_2d.size == self.num_classes**2
        conf = bincount_2d.reshape(
            (self.num_classes, self.num_classes)
        )

        # Compute the IoU and mean IoU from the confusion matrix
        true_positive = np.diag(conf)
        false_positive = np.sum(conf, 0) - true_positive
        false_negative = np.sum(conf, 1) - true_positive

        # Just in case we get a division by 0, ignore/hide the error and
        # set the value to 1 since we predicted 0 pixels for that class and
        # and the batch has 0 pixels for that same class
        with np.errstate(divide='ignore', invalid='ignore'):
            iou = true_positive / (true_positive + false_positive + false_negative)
        iou[np.isnan(iou)] = 1

        return np.mean(iou).astype(np.float32)

"""### 모델 구성"""

from tensorflow.keras.models import *
from tensorflow.keras.layers import *

IMAGE_ORDERING = 'channels_last'
n_classes = 32 # 클래스 수

inputs = Input((128, 128, 3)) # 입력 Image
s = Lambda(lambda x: x / 255)(inputs) #Inputs Normalization

'''
  FCN 알고리즘
  ## Encoder
  # Block : Conv-Pooling 구조로 Feature extractor읕 구성함
  Conv2D(filter, kernel_size, activation='relu', padding='same', name, data_format)
  MaxPooling2D(pooling_layer size, pooling_layer stride, name, data_format)

  ## Decoder
  # pred3, pred4, pred5 : Encoder output에 Tranposed Convolution 진행한 Upsampling 결과
  # final : o(add(pred3, pred4, pred5))의 maxpooling으로 나온 prediction을 reshape
'''

# Block 1
x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(s) #활성함수 : relu
x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)
x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)
f1 = x #각 Block의 pooling layer

# Block 2
x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)
x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)
x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)
f2 = x

# Block 3
x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)
x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)
x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)
x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)
f3 = x

pred3= Conv2DTranspose( n_classes , kernel_size=(16,16) ,  strides=(16,16) , use_bias=False ,  data_format=IMAGE_ORDERING )(f3)

# Block 4
x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)
x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)
f4 = x

pred4= Conv2DTranspose( n_classes , kernel_size=(32,32) ,  strides=(32,32) , use_bias=False ,  data_format=IMAGE_ORDERING )(f4)

# Block 5
x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)
x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)
f5 = x

pred5= Conv2DTranspose( n_classes , kernel_size=(64,64) ,  strides=(64,64) , use_bias=False ,  data_format=IMAGE_ORDERING )(f5)


o = Add(name="add")([pred3, pred4, pred5]) # o : upsampling 결과

o = MaxPooling2D((2, 2), strides=(2, 2), name='final', data_format=IMAGE_ORDERING)(o)
o = ( Conv2D( n_classes ,  ( 1 , 1 ) ,kernel_initializer='he_normal' , data_format=IMAGE_ORDERING))(o) #Reshape : 1X1 Convolution 
#o = Conv2DTranspose( n_classes , kernel_size=(32,32) ,  strides=(32,32) , use_bias=False ,  data_format=IMAGE_ORDERING )(o)
    
o = (Activation('softmax'))(o) # 활성함수 : softmax


# fcn 함수 인자 정의
fcn_model = Model([inputs] , [o] )

"""### 모델 학습과정 설정"""

# MeanIoU 함수 적용
miou_metric = MeanIoU(N_CLASSES)

# fcn 파라미터 정의
fcn_model.compile(
            loss="mean_squared_error", optimizer='adam', metrics=['accuracy', miou_metric.mean_iou])

# 모델 구조 확인
fcn_model.summary()

"""### 모델 학"""

EPOCHS = 100 # epoch 수 정의
BATCH_SIZE = 4   # batch_size 정의

# fcn_model 모델 학습
history_fcn = fcn_model.fit(np.array(x_train), np.array(y_train),
                    validation_data=(np.array(x_val), np.array(y_val)), 
                    epochs=EPOCHS,
                    batch_size=BATCH_SIZE,
                    verbose=2)EPOCHS = 100 # epoch 수 정의
BATCH_SIZE = 4   # batch_size 정의

# fcn_model 모델 학습
history_fcn = fcn_model.fit(np.array(x_train), np.array(y_train),
                    validation_data=(np.array(x_val), np.array(y_val)), 
                    epochs=EPOCHS,
                    batch_size=BATCH_SIZE,
                    verbose=2)

"""### 학습 결과 시각화"""

'''
  train_loss_fcn: 학습 데이터 loss 값
  train_accuracy_fcn: 학습 데이터 accuracy 값
  train_miou_fcn: 학습 데이터 mean_iou 값
  val_loss_fcn: 검증 데이터 loss 값
  val_accuracy_fcn: 검증 데이터 accuracy 값
  val_miou_fcn: 검증 데이터 mean_iou 값
'''

train_loss_fcn = history_fcn.history['loss']
train_accuracy_fcn = history_fcn.history['accuracy']
train_miou_fcn = history_fcn.history['mean_iou']
val_loss_fcn = history_fcn.history['val_loss']
val_accuracy_fcn = history_fcn.history['val_accuracy']
val_miou_fcn = history_fcn.history['val_mean_iou']

# loss, accuracy, mean_iou 시각화(범위: epoch 수)
epoch = range(0, EPOCHS)

plt.figure(figsize=(23,8))
plt.subplot(1,3,1)
sns.lineplot(epoch, train_loss_fcn)
sns.lineplot(epoch, val_loss_fcn)
plt.title('Loss', size=14)
plt.legend(['train_loss', 'val_loss'])

plt.subplot(1,3,2)
sns.lineplot(epoch, train_accuracy_fcn)
sns.lineplot(epoch, val_accuracy_fcn)
plt.title('Accuracy', size=14)
plt.legend(['train_accuracy', 'val_accuracy'])

plt.subplot(1,3,3)
sns.lineplot(epoch, train_miou_fcn)
sns.lineplot(epoch, val_miou_fcn)
plt.title('Miou', size=14)
plt.legend(['train_miou', 'val_miou'])
plt.show()

"""### 테스트 데이터 예측 및 결 """

# 테스트 데이터 예측
prediction_fcn = fcn_model.predict(np.array(x_test))

# 색상 코드 호출
color_codes_list = [color_codes[i] for i in color_codes.keys()]

# get_rgb_image 함수 정의
def get_rgb_image(prediction, n_classes, color_codes):
  
    '''
      output_height: 세로 크기(128) 정의
      output_width: 가로 크기(128) 정의
      seg_img: (128,128,3) shape 0으로 정의
   '''
    output_height = prediction.shape[0]
    output_width = prediction.shape[1]
    seg_img = np.zeros((output_height, output_width, 3))

    # 예측값에서 RGB 이미지를 반환
    for c in range(n_classes):
        seg_img[:, :, 0] += ((prediction[:, :, c])*(color_codes[c][0])).astype('uint8')
        seg_img[:, :, 1] += ((prediction[:, :, c])*(color_codes[c][1])).astype('uint8')
        seg_img[:, :, 2] += ((prediction[:, :, c])*(color_codes[c][2])).astype('uint8')
    return seg_img / 255.0

# 예측 이미지 시각화
for i in range(1,10):
    plt.figure(figsize=(15, 6))
    plt.subplot(1,3,1)
    plt.imshow(x_test[i])
    plt.title('Original Image')

    plt.subplot(1,3,2)
    plt.imshow(get_rgb_image(y_test[i], N_CLASSES, color_codes_list))
    plt.title('Labeled Image')
   
    plt.subplot(1,3,3)
    plt.imshow(get_rgb_image(prediction_fcn[i], N_CLASSES, color_codes_list))
    plt.title('Predicted Image')
    plt.show()

# 테스트 데이터 MeanIou 값
fcn_test_miou = tf.keras.metrics.MeanIoU(num_classes=32)
fcn_test_miou.update_state(np.array(y_test), prediction_fcn)
fcn_test_miou.result().numpy()
